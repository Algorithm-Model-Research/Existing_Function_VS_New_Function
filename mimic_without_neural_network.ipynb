{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom operator import itemgetter    \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nget_ipython().magic(u'matplotlib inline')\nplt.style.use('ggplot')\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import preprocessing\nfrom sklearn.impute import SimpleImputer\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\nfrom sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC \nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, ShuffleSplit\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_curve, average_precision_score, auc\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nfrom mlxtend.plotting import plot_learning_curves\nfrom mlxtend.preprocessing import shuffle_arrays_unison\n\nprint(os.getcwd())\nprint(\"Modules imported \\n\")\nimport os","metadata":{"_uuid":"be5e7a1a7278c138e277e90b019db4961154c731","execution":{"iopub.status.busy":"2022-05-07T05:22:44.438124Z","iopub.execute_input":"2022-05-07T05:22:44.438512Z","iopub.status.idle":"2022-05-07T05:22:45.801808Z","shell.execute_reply.started":"2022-05-07T05:22:44.438404Z","shell.execute_reply":"2022-05-07T05:22:45.800922Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/working\nModules imported \n\n","output_type":"stream"}]},{"cell_type":"code","source":"mimic_data = pd.read_csv('https://raw.githubusercontent.com/RonaldsonBellande/AI_Prioritization/master/mimic3d.csv')\ndata_full = mimic_data.drop('hadm_id', 1)\nprint(\"With ID\", mimic_data.shape)\nprint(\"Without ID\",data_full.shape)","metadata":{"_uuid":"d624986c6d662b3dec980c593981fb913cb00c01","execution":{"iopub.status.busy":"2022-05-07T05:22:45.803209Z","iopub.execute_input":"2022-05-07T05:22:45.803462Z","iopub.status.idle":"2022-05-07T05:22:46.509881Z","shell.execute_reply.started":"2022-05-07T05:22:45.803434Z","shell.execute_reply":"2022-05-07T05:22:46.509252Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"With ID (58976, 28)\nWithout ID (58976, 27)\n","output_type":"stream"}]},{"cell_type":"code","source":"data_full.info()\ndata_full.describe()","metadata":{"_uuid":"a3d700d5763270c86b368668e9ef7af00372c79c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_full.head(10)","metadata":{"_uuid":"1fce3fd763d30cf516d00815bb386cd95cea14ec","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = data_full['LOSgroupNum']\nX = data_full.drop('LOSgroupNum', 1)\nX = X.drop('LOSdays', 1)\nX = X.drop('ExpiredHospital', 1)\nX = X.drop('AdmitDiagnosis', 1)\nX = X.drop('AdmitProcedure', 1)\nX = X.drop('marital_status', 1)\nX = X.drop('ethnicity', 1)\nX = X.drop('religion', 1)\nX = X.drop('insurance', 1)\n\nprint(\"y - With Labels\", y)\nprint(\"X - With no Labels and no ID \", X)","metadata":{"_uuid":"798b9834d32ba534e5aca36d5763b9624fe00565"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_full.groupby('LOSgroupNum').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_type').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_location').size().plot.bar()\nplt.show()","metadata":{"_uuid":"dfe87481713cb5fd1ca62ec4ad6178eea875fc85"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.info()\nX.describe()","metadata":{"_uuid":"c2a17ce91d1523ebda4d7ecf75cc6a2b055f814b","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_columns = [\n                    'gender',                     \n                    'admit_type',\n                    'admit_location'\n                      ]\n\nfor col in categorical_columns:\n    if col in X.columns:\n        one_hot_encoded = pd.get_dummies(X[col])\n        X = X.drop(col, axis=1)\n        X = X.join(one_hot_encoded, lsuffix='_left', rsuffix='_right')\n        \nprint(X.shape)","metadata":{"_uuid":"45c8a4a2737cf1a44f6be54e4d4424530e59b096"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_full.shape)\nprint(X.shape)\nX_copy = X.copy()\nY_copy = y.copy()","metadata":{"_uuid":"60be44d230f432f3f087f15a238feb21deb68bbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalize X values \nx_value = X_copy.values\nscaler = preprocessing.StandardScaler()\nx_scaled = scaler.fit_transform(X)\nX_normalized = pd.DataFrame(x_scaled, columns=X_copy.columns)\nprint(X_normalized)","metadata":{"_uuid":"63cee0b5231c742bacfb4318b16959e4f6394b1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)\n\nprint('Y_train', y_train)\nprint('Y_test', y_test)","metadata":{"_uuid":"aefe400392c73d77e55bf9f2410e7b725df2e77c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 42\nscoring = 'accuracy' \n\nMymodels = []\nMymodels.append(('RandomForestClassifier', RandomForestClassifier()))\nMymodels.append(('SGDclassifier', SGDClassifier()))\nMymodels.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n\nresults = []\nnames = []\nfor name, model in Mymodels:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg) ","metadata":{"_uuid":"f03ccf0923716b07035356abcf3acb4a51d23025"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier()\n\nparam_grid = [{},]\n\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring=scoring)\ngrid_search.fit(X_normalized, y)\n\nprint(grid_search.best_estimator_)","metadata":{"_uuid":"e0d67a66679ee59af083b102408c69db5646ba33"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)","metadata":{"_uuid":"5a406c3bcd3c161727af4b5dcab74dca35daf853"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainFinalFI = X_normalized\nyFinalFI = y\n\nmodel.fit(trainFinalFI,yFinalFI)\n\nFI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model[FI_model[\"Feature Importance\"] > 0.005].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\nplt.xticks(rotation=90)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"_uuid":"b9097a12c41f10f3b86e0915577ce0d781e4758c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model=FI_model.sort_values('Feature Importance', ascending = False)\nprint(FI_model[FI_model[\"Feature Importance\"] > 0.001])","metadata":{"_uuid":"49522e46d392dfcf95d60a54481d1dce22cdef30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Error\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = 1-np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = 1-np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","metadata":{"_uuid":"9e4dc0ce72a8131e32acda585f4b76061034f7f0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title = \"Learning Curves \"\ncv = ShuffleSplit(n_splits=7, test_size=0.2)\nplot_learning_curve(model, title, X_train, y_train, cv=cv, n_jobs=4)","metadata":{"_uuid":"afe92f8617e5290fc0317d2331947583282bac65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","metadata":{"_uuid":"91574fedd82e85ae7d616e23f4c5174213926f24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model FINAL fit and evaluation on test\n\nmodel.fit(X_train, y_train)\nfinal_predictions = model.predict(X_test)\n\nconfusion_mx = confusion_matrix(y_test, final_predictions)","metadata":{"_uuid":"e3c18714aca39c174cd2c2d747f3ee23c2491362"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm,target_names,title='Confusion Matrix',cmap=None,\n                          normalize=False):\n    import itertools\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n","metadata":{"_uuid":"0f5410cd3c3f20bbee11842580a4cb0fb828b883"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(confusion_mx, \n                      normalize    = False,\n                      target_names = [0,1,2,3],\n                      title        = \"Confusion Matrix\")","metadata":{"_uuid":"9c064c815e2cb9ca1fa26681cc8d68998571911a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NumClasses = 4\n\nTP = 0\nTN = 0\nFP = 0\nFN = 0\n\nfor z in range(NumClasses):\n# One class at a time - calculate confusion matrix\n    SumCM = np.sum(confusion_mx)\n    TPz = confusion_mx[z,z]\n    FNz = np.sum(confusion_mx[z,:], axis=0) -TPz\n    FPz = np.sum(confusion_mx[:,z], axis=0) -TPz\n    TNz = SumCM - (TPz+FNz+FPz)\n    print('Class ',z)\n  \n\n    # Create conf matrix for class z\n    cmZ = np.zeros([2, 2], dtype=np.int32)\n    cmZ[0,0] = TNz\n    cmZ[0,1] = FPz\n    cmZ[1,0] = FNz\n    cmZ[1,1] = TPz\n\n    plot_confusion_matrix(cmZ, \n                          normalize    = False,\n                          target_names = [0,1],\n                          title        = \"Confusion matrix for one class \")\n\n    accuracy = (TPz+TNz)/(TPz+TNz+FPz+FNz)\n    recall = TPz/(TPz+FNz)\n    precision = TPz/(TPz+FPz)\n    f1score = 2*recall*precision/(recall+precision)\n    \n    print('TPz ',TPz)\n    print('FNz ',FNz)\n    print('FPz ',FPz)\n    print('TNz ',TNz)\n    print('sum ', TPz+TNz+FPz+FNz)\n    print(cmZ)\n    print('Sum of CM ', np.sum(cmZ))\n    print ('accuracy ',round(accuracy,4))\n    print('recall ', round(recall,4))\n    print('precision ', round(precision,4))\n    print('F1Score ', round(f1score,4))\n    print('-'*40)\n    \n    TP = TP + TPz\n    TN = TN + TNz\n    FP = FP + FPz\n    FN = FN + FNz\nprint ('TN: ', TN)\nprint ('FP: ', FP)\nprint ('FN: ', FN)\nprint ('TP: ', TP)\nprint('_'*40)","metadata":{"_uuid":"837aba4cbecd2bde6bdaab1cb8417348ee823dea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matix for ALL Classes')\n\nTP = TP / NumClasses\nTN = TN / NumClasses\nFP = FP / NumClasses\nFN = FN / NumClasses\n\n\ncm = np.zeros([2, 2], dtype=np.int32)\ncm[0,0] = TN\ncm[0,1] = FP\ncm[1,0] = FN\ncm[1,1] = TP\n\nplot_confusion_matrix(cm, \n                      normalize    = False,\n                      target_names = [0,1],\n                      title        = \"Confusion Matrix\")\n","metadata":{"_uuid":"1d04b2db06faa9b5a97616249890ac562ec4ed4e"},"execution_count":null,"outputs":[]}]}